{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "  * Find the k-nearest neighbors of a given query input\n",
    "  * Predict the output for the query input using the k-nearest neighbors\n",
    "  * Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we use a subset of the King County housing dataset created by randomly selecting 40% of the houses in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to wang_jasmine@msn.com and will expire on December 15, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-21484 - Server binary: C:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\unity_server.exe - Server log: C:\\Users\\Jas\\AppData\\Local\\Temp\\graphlab_server_1454573447.log.0\n",
      "[INFO] GraphLab Server Version: 1.8.1\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('C:\\Users\\Jas\\Documents\\UofWash_ML\\kc_house_data_small.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently compute pairwise distances among data points, we will convert the SFrame into a 2D Numpy array. First import the numpy library and then copy and paste `get_numpy_data()` from the second notebook of Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "     \n",
    "    features_sframe = data[features]\n",
    "    \n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_matrix = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the `normalize_features()` function from Week 5 that normalizes all feature columns to unit norm. Paste this function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis = 0)\n",
    "    normalized_features = feature_matrix / norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_and_validation, test) = sales.random_split(.8, seed=1) # initial train/test split\n",
    "(train, validation) = train_and_validation.random_split(.8, seed=1) # split training set into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all of the numerical inputs listed in `feature_list`, transform the training, test, and validation SFrames into Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the \"distance\" between two given houses.  We will take our **query house** to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01163464  0.00602491  0.00703685  0.00181386  0.0085295   0.\n",
      "  0.          0.0116321   0.01216718  0.00811747  0.          0.01333931\n",
      "  0.          0.01343686 -0.01345621  0.00861561  0.00229178]\n"
     ]
    }
   ],
   "source": [
    "print features_train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the 10th row (index 9) of the training feature matrix. Again, you get an 18-dimensional vector with components between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346254  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print features_train[9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION ***\n",
    "\n",
    "What is the Euclidean distance between the query house and the 10th house of the training set? \n",
    "\n",
    "Note: Do not use the `np.linalg.norm` function; use `np.sqrt`, `np.sum`, and the power operator (`**`) instead. The latter approach is more easily adapted to computing multiple distances at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106660786871\n"
     ]
    }
   ],
   "source": [
    "#for i in range(len(feature_list)):\n",
    "euc_distance = np.sqrt(np.sum(features_train[9]-features_test[0])**2)\n",
    "print euc_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute multiple distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to do nearest neighbor regression, we need to compute the distance between our query house and *all* houses in the training set.  \n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (`features_test[0]`) to the first 10 houses of the training set (`features_train[0:10]`) and then search for the nearest neighbor within this small set of houses.  Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.060274709173\n",
      "1 0.0854688114883\n",
      "2 0.0614994643712\n",
      "3 0.0534027397882\n",
      "4 0.0584448406394\n",
      "5 0.0598792151018\n",
      "6 0.0546314049726\n",
      "7 0.0554310832416\n",
      "8 0.052383627841\n",
      "9 0.0597235937167\n"
     ]
    }
   ],
   "source": [
    "#j = 0  no need to build for loop for all features, numpy array vectorization takes care of them!\n",
    "#distance_10 = []\n",
    "\n",
    "#for  i in range (len(features_train[0:10])):     \n",
    "for i in range(10):\n",
    "    euc_distance = np.sqrt(np.sum((features_train[i] - features_test[0])**2))\n",
    "    a = np.sort(euc_distance)\n",
    "    b = np.argsort(a)\n",
    "    #print a,b\n",
    "    print i,euc_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Among the first 10 training houses, which house is the closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# answer to quiz 1: index 8, No 9th house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the Numpy functions can be **vectorized**, applying the same operation over multiple values or vectors.  We now walk through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following loop that computes the element-wise difference between the features of the query house (`features_test[0]`) and the first 3 training houses (`features_train[0:3]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -1.05552733e-02\n",
      "   2.08673616e-04  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03  -5.50336860e-03  -2.48168183e-02\n",
      "  -1.63756198e-04   0.00000000e+00  -1.70072004e-05   1.30577772e-05\n",
      "  -5.14364795e-03   6.69281453e-04]\n",
      "[  0.00000000e+00  -3.87821276e-03  -4.51868214e-03  -2.26610387e-03\n",
      "   7.19763456e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03   1.30705004e-03  -1.45830788e-02\n",
      "  -1.91048898e-04   6.65082271e-02   4.23240653e-05   6.22415897e-06\n",
      "  -2.89330197e-03   1.47606982e-03]\n",
      "[  0.00000000e+00  -7.75642553e-03  -1.20498190e-02  -1.30002801e-02\n",
      "   1.60518166e-03  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -5.21450589e-03  -8.32384500e-03  -2.48168183e-02\n",
      "  -3.13866046e-04   0.00000000e+00   4.71047219e-05   1.56530415e-05\n",
      "   3.72914476e-03   1.64764925e-03]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(3):\n",
    "    print features_train[i]-features_test[0]\n",
    "  \n",
    "    # should print 3 vectors of length 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subtraction operator (`-`) in Numpy is vectorized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -1.05552733e-02\n",
      "    2.08673616e-04  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "    0.00000000e+00  -3.47633726e-03  -5.50336860e-03  -2.48168183e-02\n",
      "   -1.63756198e-04   0.00000000e+00  -1.70072004e-05   1.30577772e-05\n",
      "   -5.14364795e-03   6.69281453e-04]\n",
      " [  0.00000000e+00  -3.87821276e-03  -4.51868214e-03  -2.26610387e-03\n",
      "    7.19763456e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "    0.00000000e+00  -3.47633726e-03   1.30705004e-03  -1.45830788e-02\n",
      "   -1.91048898e-04   6.65082271e-02   4.23240653e-05   6.22415897e-06\n",
      "   -2.89330197e-03   1.47606982e-03]\n",
      " [  0.00000000e+00  -7.75642553e-03  -1.20498190e-02  -1.30002801e-02\n",
      "    1.60518166e-03  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "    0.00000000e+00  -5.21450589e-03  -8.32384500e-03  -2.48168183e-02\n",
      "   -3.13866046e-04   0.00000000e+00   4.71047219e-05   1.56530415e-05\n",
      "    3.72914476e-03   1.64764925e-03]]\n"
     ]
    }
   ],
   "source": [
    "print features_train[0:3] - features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of this vectorized operation is identical to that of the loop above, which can be verified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# verify that vectorization works\n",
    "results = features_train[0:3] - features_test[0]\n",
    "print results[0] - (features_train[0]-features_test[0])\n",
    "# should print all 0's if results[0] == (features_train[0]-features_test[0])\n",
    "print results[1] - (features_train[1]-features_test[0])\n",
    "# should print all 0's if results[1] == (features_train[1]-features_test[0])\n",
    "print results[2] - (features_train[2]-features_test[0])\n",
    "# should print all 0's if results[2] == (features_train[2]-features_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: it is a good idea to write tests like this cell whenever you are vectorizing a complicated operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 1-nearest neighbor regression\n",
    "\n",
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable `diff` such that `diff[i]` gives the element-wise difference between the features of the query house and the `i`-th training house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   0.00000000e+00  -3.01245476e-03  -2.26610387e-03\n",
      "   6.97611949e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -1.73816863e-03   4.05873434e-03  -2.48168183e-02\n",
      "   1.77402548e-04   0.00000000e+00   3.84492094e-05   2.91798436e-05\n",
      "   3.15048437e-03   8.21796500e-04]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print features_train[i]-features_test[0]\n",
    "#print diff\n",
    "\n",
    "#print np.sum(diff[-1]**2)\n",
    "#print np.dot(diff[-1],diff[-1])\n",
    "i=len(features_train)\n",
    "diff=features_train[0:i]-features_test[0]\n",
    "    \n",
    "print diff[10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the code above, run the following cell, which should output a value -0.0934339605842:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0934339605842\n"
     ]
    }
   ],
   "source": [
    "print diff[-1].sum() # sum of the feature differences between the query and last training house\n",
    "# should print -0.0934339605842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in `diff`, square each, and take the sum over feature indices.  That is, compute the sum of square feature differences for each training house (row in `diff`).\n",
    "\n",
    "By default, `np.sum` sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the `axis` parameter described in the `np.sum` [documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.sum.html). In particular, `axis=1` computes the sum across each row.\n",
    "\n",
    "Below, we compute this sum of square feature differences for all training houses and verify that the output for the 16th house in the training set is equivalent to having examined only the 16th row of `diff` and computing the sum of squares on that row alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00330705902879\n",
      "0.00330705902879\n"
     ]
    }
   ],
   "source": [
    "print np.sum(diff**2, axis=1)[15] # take sum of squares across each row, and print the 16th sum\n",
    "print np.sum(diff[15]**2) # print the sum of squares for the 16th row -- should be same as above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this result in mind, write a single-line expression to compute the Euclidean distances between the query house and all houses in the training set. Assign the result to a variable `distances`.\n",
    "\n",
    "**Hint**: Do not forget to take the square root of the sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0237082324496\n"
     ]
    }
   ],
   "source": [
    "n = len(features_train)\n",
    "#print n\n",
    "diff = features_train[0:101] - features_test[0]\n",
    "distances = np.sqrt(np.sum(diff**2, axis=1))[100]\n",
    "print distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the code above, run the following cell, which should output a value 0.0237082324496:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0237082324496\n"
     ]
    }
   ],
   "source": [
    "\n",
    "diff = features_train[0:101] - features_test[0]\n",
    "distances = np.sqrt(np.sum(diff**2, axis=1))[100]\n",
    "print distances\n",
    "\n",
    "#print np.sqrt(np.dot(diff[0:100].transpose(),diff[0:100])) # Euclidean distance between the query house and the 101th training house\n",
    "# should print 0.0237082324496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0597235937167\n"
     ]
    }
   ],
   "source": [
    "# quiz 1\n",
    "diff = features_train[9] - features_test[0]\n",
    "distances = np.sqrt(np.sum(diff**2))\n",
    "print distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to write a function that computes the distances from a query house to all training houses. The function should take two parameters: (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distance_1nn(feature_matrix, query_index):\n",
    "    dist2nn = 999999.\n",
    "    one_nn = []\n",
    "    n=len(feature_matrix)\n",
    "    j=0\n",
    "    for i in xrange(0,n):\n",
    "        diff = feature_matrix[i] - features_test[query_index]\n",
    "        euc_dist = np.sqrt(np.sum(diff**2))\n",
    "        if euc_dist < dist2nn:\n",
    "             one_nn = feature_matrix[i]\n",
    "             dist2nn = euc_dist\n",
    "             j = i\n",
    "\n",
    "    \n",
    "    return (one_nn,dist2nn,i,diff,euc_dist,j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026379415342667443"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not in use, not correct\n",
    "n=len(features_train)\n",
    "diff = features_train[0:n] - features_test[2]\n",
    "        \n",
    "euc_dist = np.sqrt(np.sum(diff**2, axis=1))[n-1]\n",
    "#One_nn = sorted(euc_dist)\n",
    "euc_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "\n",
    "1.  Take the query house to be third house of the test set (`features_test[2]`).  What is the index of the house in the training set that is closest to this query house? 382\n",
    "2.  What is the predicted value of the query house based on 1-nearest neighbor regression? 249000 0.026379415342667439,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.01345102,  0.01163464,  0.00903736,  0.01013783,  0.00264759,\n",
      "        0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
      "        0.006948  ,  0.0176532 ,  0.01344165,  0.        ,  0.01341151,\n",
      "       -0.01344709,  0.00925857,  0.00340725]), 0.0028604952675079271, 5526, array([  0.00000000e+00,   0.00000000e+00,   4.51868214e-03,\n",
      "         5.96343124e-05,  -1.68511971e-03,   1.70590041e-02,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         1.73816863e-03,   5.09061595e-03,  -1.86765746e-02,\n",
      "         4.16213670e-04,   0.00000000e+00,   1.21263428e-06,\n",
      "        -4.68414636e-06,   6.42955993e-05,  -1.91698433e-03]), 0.026379415342667439, 382)\n",
      "249000\n"
     ]
    }
   ],
   "source": [
    "a = distance_1nn(features_train, 2)\n",
    "print a\n",
    "print output_train[382]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a *set* of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors\n",
    "\n",
    "Using the functions above, implement a function that takes in\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses; and\n",
    " * the feature vector of the query house\n",
    " \n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n",
    "**Hint**: Look at the [documentation for `np.argsort`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "a = [1, 2, 4, 5] \n",
    "bisect.insort(a, 3) \n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 12, 14, 15, 19]\n",
      "[5, 10, 12, 13, 14, 15, 19] 3\n"
     ]
    }
   ],
   "source": [
    "a = [15, 12, 10,14,19,5]\n",
    "b = sorted(a)\n",
    "print b # --> b = [10, 12, 15]\n",
    "c = 13\n",
    "for i in range(len(b)):\n",
    "    if b[i] > c:\n",
    "        index = i\n",
    "        break\n",
    "d = b[:i] + [c] + b[i:]\n",
    "print d, index # --> d = [10, 12, 13, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.   5.   8.   8.  12.  13.  15.] [3 1 2 6 4 0 5]\n",
      "[  13.    5.    8.    4.   12.  100.   15.    8.] [3 1 2 6 4] [[  9.99999999e+08   9.99999999e+08   9.99999999e+08   9.99999999e+08\n",
      "    9.99999999e+08   9.99999999e+08   9.99999999e+08   9.99999999e+08]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([13.,5.,8.,4.,12.,15.,8])\n",
    "a1 = np.sort(a)\n",
    "b = np.argsort(a)\n",
    "z = np.argsort(a)[0:5]\n",
    "print a1,b\n",
    "c = np.insert(a,5,100)\n",
    "d = np.full((1,8), 999999999.)\n",
    "print c,z,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 22 33 44 66] [ 22 101  44 100  66 100 101  99  99  99  11  33  99]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([99,99,99,99,99,11,33,99])\n",
    "b = np.array([22,101,44,100,66,77])\n",
    "for j in range (0,5):\n",
    "    if b[j] < a[j]:\n",
    "        a = np.insert(a,j,b[j])\n",
    "        a[j+1:5] = a[j:4]\n",
    "        \n",
    "    elif b[j] > a[j] and j < a[j+1]:\n",
    "        a = np.insert(a,j,b[j])\n",
    "        a[j+1:5] = a[j:4]\n",
    "\n",
    "        \n",
    "b = np.sort(a)[0:5]\n",
    "print b ,a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def distance_knn(k, feature_matrix, query_index):\n",
    "    n = len(feature_matrix)\n",
    "    index_knn = []  # array with k elements to describe the index of k houses\n",
    "  \n",
    "    dist2knn = np.full((1,k), 999999999.)  # array with k elements for distance between k houses and the query house\n",
    "    knn = []\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        diff = feature_matrix[i] - features_test[query_index]\n",
    "        euc_dist = np.sqrt(np.sum(diff**2))\n",
    "        \n",
    "\n",
    "        for j in range(0,k):\n",
    "            knn = knn.append(distances[i][0])\n",
    "            if euc_dist <= dist2knn[j]:\n",
    "                dist2knn = np.insert(dist2knn,j,euc_dist)\n",
    "                dist2knn[j+1:k] = dist2knn[j:k-1]\n",
    "                index_knn = np.insert(index_knn,j,j)\n",
    "                index_knn[j+1:k] = index_knn[j:k-1]\n",
    "            elif euc_dist > dist2knn[j] and euc_dist < dist2knn[j+1]:\n",
    "         \n",
    "                dist2knn = np.insert(dist2knn, j, euc_dist)\n",
    "                dist2knn[j+1:k] = dist2knn[j:k-1]\n",
    "                dist2knn = euc_dist\n",
    "\n",
    "                #index_knn = index_knn(feature_matrix[index_knn] = dist2knn)\n",
    "            \n",
    "            \n",
    "            \n",
    "            i += 1  \n",
    "        \n",
    "        index_knn =np.argsort(dist2knn)\n",
    "        \n",
    "    return (dist2knn,index_knn)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, feature_matrix, query_index):\n",
    "    index_knn = []\n",
    "    dist2knn = np.ones(k) * 9999\n",
    "    n = len(feature_matrix)\n",
    "    for i in range(n):\n",
    "        \n",
    "        euc_dist = np.sqrt(sum((features_train[0:i] - features_test[0])**2))\n",
    "                \n",
    "        for j in range(0,k):\n",
    "            \n",
    "            if euc_dist[i] <= dist2knn[j]:\n",
    "               \n",
    "                index_knn = np.insert(index_knn,j,i)\n",
    "                index_knn[j+1:k] = index_knn[j:k-1]\n",
    "            #elif euc_dist > dist2knn[j] and euc_dist < dist2knn[j+1]:\n",
    "         \n",
    "                #dist2knn = np.insert(dist2knn, j, euc_dist)\n",
    "                #dist2knn[j+1:k] = dist2knn[j:k-1]\n",
    "                #dist2knn = euc_dist\n",
    "\n",
    "        neighbors = index_knn\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-494-791a38821e94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mk_nearest_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-493-831f3d320c2c>\u001b[0m in \u001b[0;36mk_nearest_neighbors\u001b[1;34m(k, feature_matrix, query_index)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0meuc_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdist2knn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mindex_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_knn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "model2 =  k_nearest_neighbors(5, feature_matrix=features_train, query_index=2)\n",
    "print model2, len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5527 [  0.00000000e+00   5.48462109e-03   1.31309859e-02   1.61342503e-02\n",
      "   2.86724417e-03   1.27942531e-02   0.00000000e+00   0.00000000e+00\n",
      "   1.09668507e-02   3.88666321e-03   1.61268714e-02   4.95280217e-02\n",
      "   4.99585021e-04   6.65082271e-02   1.28058584e-04   3.68099667e-05\n",
      "   9.83344388e-03   2.70135670e-03] [ 0  7  6 15 14 12 17  4  9  1]\n"
     ]
    }
   ],
   "source": [
    "    n = len(features_train)    \n",
    "    diff = np.sqrt(sum((features_train[0:10,:] - features_test[2])**2))\n",
    "    \n",
    "    index = np.argsort(diff)[0:10]\n",
    "    print n,diff, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.   5.   8.   4.  15.   9.] [ 0.  1.  9.] [1 3 2] 5 [  64.    0.    9.    1.  100.   16.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([13.,5.,8.,4.,15.,9.])  # 1st array - source array\n",
    "z = 5\n",
    "diff = (a - z)**2\n",
    "b = np.sort(diff)[0:3]   # 2nd arrray - return the top 3 from a \n",
    "c = np.argsort(diff)[0:3]\n",
    "\n",
    "print a,b,c,z,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "[  1.  13.   5.   8.   4.  15.   9.] [  1.   4.   5.   8.   9.  13.  15.] [0 4 2 3 6 1 5] [0 4 2 3 6]\n",
      "3 4\n",
      "[  4.   1.  13.   5.   8.   4.  15.   9.] [  1.   4.   4.   5.   8.   9.  13.  15.] [1 0 5 3 4 7 2 6] [1 0 5 3 4]\n",
      "4 9\n",
      "[  9.   4.   1.  13.   5.   8.   4.  15.   9.] [  1.   4.   4.   5.   8.   9.   9.  13.  15.] [2 1 6 4 5 0 8 3 7] [2 1 6 4 5]\n",
      "5 16\n",
      "[  9.   4.   1.  13.   5.   8.   4.  15.   9.] [  1.   4.   4.   5.   8.   9.   9.  13.  15.] [2 1 6 4 5 0 8 3 7] [2 1 6 4 5]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([13.,5.,8.,4.,15.,9.])\n",
    "\n",
    "for i in range(1,5):\n",
    "    \n",
    "    j = i**2\n",
    "    if np.max(a)>j:\n",
    "        a = np.insert(a,0,j)\n",
    "        b = np.sort(a)\n",
    "        c = np.argsort(a)\n",
    "        d = np.argsort(a)[0:5]\n",
    "    i += 1\n",
    "    print i,j\n",
    "    print a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def distance_knn(k, feature_matrix, query_index):\n",
    "    dist2knn = np.full((1,k),999999.)\n",
    "    index_knn = []\n",
    "    \n",
    "    for i in range(0,len(feature_matrix)):\n",
    "        diff = feature_matrix[i] - features_test[query_index]\n",
    "        euc_dist = np.sqrt(np.sum(diff**2))\n",
    "        dist2knn = np.insert(dist2knn,0,euc_dist)\n",
    "        index_knn = np.insert(index_knn,0,i)\n",
    "        dist2knn = np.sort(dist2knn)[0:k]\n",
    "                \n",
    "       \n",
    "        \n",
    "    return (dist2knn,index_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-476-c42750dcd852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdistance_knn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-468-3296e28eb115>\u001b[0m in \u001b[0;36mdistance_knn\u001b[1;34m(k, feature_matrix, query_index)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0meuc_dist\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdist2knn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mdist2knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist2knn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meuc_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mdist2knn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist2knn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "model1 =  distance_knn(5, feature_matrix=features_train, query_index=2)\n",
    "print model1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_model = graphlab.nearest_neighbors.create(features_train,features=[:],\n",
    "                                             label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Take the query house to be third house of the test set (`features_test[2]`).  What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_prediction(k,features_train,query_house):\n",
    "    \n",
    "    index=np.zeros(k)\n",
    "    distance =np.zeros(k)\n",
    "    (index,distance) = distance_knn(k,features_train,query_house)\n",
    "    \n",
    "    price = sum(output_train[index])/k\n",
    "    \n",
    "    return (price, query_house)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413987,\n",
       " array([ 0.01345102,  0.01163464,  0.01054359,  0.00906442,  0.00204821,\n",
       "         0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
       "         0.00543458,  0.01867657,  0.01329154,  0.        ,  0.01348883,\n",
       "        -0.01346136,  0.00977293,  0.00252907]))"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_prediction(4,features_train,features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set**. The function should have the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 635000.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "knn.fit(features_train, output_train)\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(features_test[0])\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Again taking the query house to be third house of the test set (`features_test[2]`), predict the value of the query house using k-nearest neighbors with `k=4` and the simple averaging method described and implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900, 538000, 180000, ..., 507250, 610685, 360000], dtype=int64)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this predicted value using 4-nearest neighbors to the predicted value using 1-nearest neighbor computed earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set.\n",
    " \n",
    "The function should return a set of predicted values, one for each house in the query set.\n",
    "\n",
    "**Hint**: To get the number of houses in the query set, use the `.shape` field of the query features matrix. See [the documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ndarray.shape.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_knn_prediction(k,features_train,query_house):\n",
    "    \n",
    "    index=np.zeros(k)\n",
    "    distance =np.zeros(k)\n",
    "    price = np.zeros(k)\n",
    "    (index,distance) = distance_knn(k,features_train,query_house)\n",
    "    \n",
    "    price = np.sort(output_train[index])\n",
    "    price_index=np.argsort(output_train[index])\n",
    "    \n",
    "    \n",
    "    return (price,price_index,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([249000, 250000, 340000, 350000, 430000, 477000, 499950, 560000,\n",
       "        700000, 750000], dtype=int64),\n",
       " array([0, 4, 7, 6, 3, 1, 2, 5, 9, 8], dtype=int64),\n",
       " array([ 382, 1149, 4087, 3142, 2751, 4556, 3372, 4584, 1666, 2283], dtype=int64))"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_knn_prediction(10,features_train,features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Make predictions for the first 10 houses in the test set using k-nearest neighbors with `k=10`. \n",
    "\n",
    "1. What is the index of the house in this query set that has the lowest predicted value? \n",
    "2. What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 1152\n",
    "#2 240000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "* For `k` in [1, 2, ..., 15]:\n",
    "    * Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    * Computes the RSS for these predictions on the VALIDATION set\n",
    "    * Stores the RSS computed above in `rss_all`\n",
    "* Report which `k` produced the lowest RSS on VALIDATION set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Depending on your computing environment, this computation may take 10-15 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_validation(k,features_train,query_house):\n",
    "    \n",
    "    rss_all = np.zeros(k)\n",
    "  \n",
    "    RSS_index = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        (price,price_index,index) = multi_knn_prediction(i,features_valid,query_house)\n",
    "        \n",
    "        rss_all[i] = sum((price - output_test[2]) **2)\n",
    "        RSS_index[i] = i\n",
    "    \n",
    "    \n",
    "    return (rss_all,RSS_index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.00000000e+00,   4.00000000e+06,   4.53836506e+10,\n",
       "          8.86476506e+10,   9.62166506e+10,   9.84256506e+10,\n",
       "          5.78674651e+11,   5.80118651e+11,   5.95002651e+11,\n",
       "          7.59432901e+11]),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]))"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_validation(10,features_valid,features_test[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To visualize the performance as a function of `k`, plot the RSS on the VALIDATION set for each considered `k` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-627-5af4bf1fec29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrss_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRSS_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrss_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bo-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\matplotlib\\pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3097\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3098\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3099\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3100\u001b[0m         \u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3101\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Jas\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must have same first dimension\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c651208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "(rss_all, RSS_index) = knn_validation(10,features_valid,features_test[2])\n",
    "plt.plot(kvals, rss_all,'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION ***\n",
    "\n",
    "What is the RSS on the TEST data using the value of k found above?  To be clear, sum over all houses in the TEST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-301-ad8f43fa3cbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = []\n",
    "knn[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "#         Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "#\n",
    "# License: BSD 3 clause (C) INRIA\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Generate sample data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "T = np.linspace(0, 5, 500)[:, np.newaxis]\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "# Add noise to targets\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "###############################################################################\n",
    "# Fit regression model\n",
    "n_neighbors = 5\n",
    "\n",
    "for i, weights in enumerate(['uniform', 'distance']):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "    y_ = knn.fit(X, y).predict(T)\n",
    "\n",
    "    plt.subplot(2, 1, i + 1)\n",
    "    plt.scatter(X, y, c='k', label='data')\n",
    "    plt.plot(T, y_, c='g', label='prediction')\n",
    "    plt.axis('tight')\n",
    "    plt.legend()\n",
    "    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors,\n",
    "                                                                weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.01355605,  0.01532602,  0.00232495,\n",
       "        0.017059  ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
       "        0.01492789,  0.01023374,  0.01331201,  0.06650823,  0.01349619,\n",
       "       -0.01346304,  0.01086596,  0.00309857])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=features_train[1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01163464,  0.01054359,  0.00906442,  0.00204821,\n",
       "        0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01216718,\n",
       "        0.00543458,  0.01867657,  0.01329154,  0.        ,  0.01348883,\n",
       "       -0.01346136,  0.00977293,  0.00252907])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=features_test[2]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def distance_knn(k, features_train, query_house):\n",
    "    n=len(features_train)\n",
    "    d=np.zeros(n)\n",
    "    knn=np.zeros(k)\n",
    "    knn1dist=np.zeros(k)\n",
    "        \n",
    "    for i in range(n):\n",
    "            \n",
    "        c = np.sqrt(sum((features_train[i] - query_house)**2))\n",
    "        d[i]= c\n",
    "        \n",
    "    knn = np.argsort(d)[0:k]    \n",
    "    knn2dist = np.sort(d)[0:k]\n",
    "\n",
    "    return (knn,knn2dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 382, 1149, 4087, 3142, 2751], dtype=int64),\n",
       " array([ 0.0028605 ,  0.00322584,  0.00350216,  0.00359315,  0.00391858]))"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_knn(5,features_train,features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.00000000e+00,  -3.87821276e-03,  -6.02490952e-03,\n",
       "         -6.08269987e-03,  -8.99543802e-04,  -8.52950206e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         -5.21450589e-03,  -1.17634504e-02,   1.76532006e-02,\n",
       "         -1.29640323e-04,   0.00000000e+00,  -4.52153864e-05,\n",
       "          1.94978509e-06,  -8.42272351e-03,  -1.07450095e-03]),\n",
       " 0.026668743852550907)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=features_train[knn[0]]-features_test[5]\n",
    "quiz6=np.sqrt(sum(e**2))\n",
    "e, quiz6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-582-486d650604e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'SFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "train('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'E' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-634-4284ef819dca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m'{:.2E}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrss_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Unknown format code 'E' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "print '{:.2E}'.format(rss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
